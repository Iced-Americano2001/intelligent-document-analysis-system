#!/bin/bash

# æ–‡æ¡£åˆ†æç³»ç»Ÿå¯åŠ¨è„šæœ¬

echo "ğŸ“„ å¯åŠ¨æ–‡æ¡£åˆ†æç³»ç»Ÿ..."

# æ£€æŸ¥Pythonç¯å¢ƒ
if ! command -v python3 &> /dev/null; then
    echo "âŒ é”™è¯¯: æœªæ‰¾åˆ°Python3"
    echo "è¯·å®‰è£…Python 3.8æˆ–æ›´é«˜ç‰ˆæœ¬"
    exit 1
fi

# æ£€æŸ¥æ˜¯å¦åœ¨è™šæ‹Ÿç¯å¢ƒä¸­
if [ -z "$VIRTUAL_ENV" ]; then
    echo "âš ï¸  å»ºè®®åœ¨è™šæ‹Ÿç¯å¢ƒä¸­è¿è¡Œæ­¤åº”ç”¨"
    echo "åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ: python3 -m venv venv"
    echo "æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ: source venv/bin/activate"
fi

# åˆ›å»ºå¿…è¦çš„ç›®å½•
echo "ğŸ“ åˆ›å»ºå¿…è¦çš„ç›®å½•..."
mkdir -p uploads
mkdir -p logs
mkdir -p temp

# æ£€æŸ¥ä¾èµ–
echo "ğŸ“¦ æ£€æŸ¥ä¾èµ–..."
pip install -r requirements.txt

# æ£€æŸ¥OllamaæœåŠ¡ï¼ˆå¦‚æœä½¿ç”¨ï¼‰
if command -v ollama &> /dev/null; then
    echo "ğŸ¤– æ£€æŸ¥OllamaæœåŠ¡..."
    if ! ollama list &> /dev/null; then
        echo "âš ï¸  OllamaæœåŠ¡æœªè¿è¡Œï¼Œæ­£åœ¨å¯åŠ¨..."
        ollama serve &
        sleep 5
    fi
    
    # æ£€æŸ¥æ¨¡å‹
    if ! ollama list | grep -q "llama3.2"; then
        echo "ğŸ“¥ ä¸‹è½½llama3.2æ¨¡å‹..."
        ollama pull llama3.2
    fi
else
    echo "â„¹ï¸  æœªå®‰è£…Ollamaï¼Œå°†ä½¿ç”¨OpenAI API"
fi

# è®¾ç½®ç¯å¢ƒå˜é‡
export PYTHONPATH="${PYTHONPATH}:$(pwd)"

# å¯åŠ¨åº”ç”¨
echo "ğŸš€ å¯åŠ¨Streamlitåº”ç”¨..."
streamlit run app.py --server.port 8501 --server.address 0.0.0.0

echo "âœ… å¯åŠ¨å®Œæˆï¼"
echo "ğŸŒ è®¿é—®åœ°å€: http://localhost:8501"
