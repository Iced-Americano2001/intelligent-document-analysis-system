### 存在的主要问题（会影响效率与质量）

- 文本直接喂给 LLM（无分块/检索/RAG），易超上下文，答案不稳定、引用不精准。
- 没有向量索引与重排，难以做高召回/高精度检索。
- 无引用页码/段落定位、无事实校验，置信度仅为占位。
- 模型提供商选择不一致：`QA_Agent` 默认指向 third_party/openai，失败后再回退到 `ollama`，容易出现你看到的模型名不匹配 404。
- 工作流编排未在 UI 中启用（已有 `BaseWorkflow` 能力但未接入）。
- 缺乏缓存与增量更新，重复解析/重复调用 LLM 浪费算力。
- PDF/OCR/表格等复杂结构的处理能力有限，难以支持“文档分析”的深层诉求。
- 无离线评测与日志追踪闭环，无法量化“回答质量”。

### 推荐的多智能体架构（面向高效与高质量）

- Orchestrator/Coordinator
  - 负责全流程编排与状态管理（复用 `BaseWorkflow`，将其接入 UI）。
- Ingestion & Parsing Agent
  - 文档格式检测、文本/版面/表格/图片抽取（必要时 OCR）。
- Chunking Agent
  - 语义分块（按标题/段落/页），生成 chunk 元数据（页码、位置）。
- Embedding & Indexing Agent
  - 建立本地向量索引（FAISS/Chroma），混合检索（BM25 + 向量）。
- Retrieval Agent
  - 基于问题检索候选片段；支持跨文档查询。
- Rerank Agent
  - 交叉编码器/LLM 轻量重排，压缩到少量高相关片段。
- QA Synthesis Agent
  - 结构化提示构造，分步推理，答案综合，保留“引用→页码→片段”。
- Verifier/Fact-check Agent
  - 对答案做证据一致性校验（抽样回查片段），打分与校正。
- Table/Chart Analysis Agent（可选）
  - 将表格转结构化数据，数值问题走计算链（pandas/简易 Code Interpreter）。
- Summarization/Report Agent（可选）
  - 输出摘要、要点列表、报告母版（按模板/行业体例）。
- Feedback & Eval Agent（可选）
  - 记录问答对、自动离线评测（RAGAS 等）、持续改进。

### 端到端工作流设计（建议）

1) 文档导入 → 解析（文本/表格/版面/OCR）→ 分块
2) 向量化与索引（落盘缓存，增量更新）
3) 用户提问 → 检索（BM25+向量）→ 重排 → 上下文预算构造（引用片段+表格摘要）
4) 答案规划 → 工具调用（表格计算/单位换算/简单代码）→ 答案综合（带引用）
5) 事实校验与打分（失败重试或降级）
6) 结果输出（答案+引用+页码+可信度）并写入缓存/日志
7) 后台异步：新文档自动向量化、索引维护、评测与数据回放

### 质量与效率关键点

- 提升质量
  - RAG（检索-重排-上下文构造）替代“整文直喂”。
  - 固定结构提示词：角色、任务、约束（必须给出处、页码、不清楚就说不知道）。
  - 自一致（少量并行、多样化解法）与Verifier二次校验。
  - 表格问题走“结构化→计算→解释”的专用链路。
- 提升效率
  - 解析/嵌入/检索结果缓存；跨会话复用向量库。
  - 并行/批量调用；小模型做检索与重排，大模型做综合。
  - 增量更新：文档变更只重算受影响片段。
  - 异步后台任务（长耗时处理不阻塞 UI）。

### 与当前系统的差距（需补齐）

- 引入向量索引与检索重排（新增 Retrieval/Rerank Agent，改造 QA 为 RAG）。
- 将 `DocumentAnalysisWorkflow` 接入 UI（现在 UI 走的是直连简化链路）。
- 统一 LLM 提供商选择策略（明确默认用本地 Ollama，或在 .env 强制指定），避免“隐式回退 + 模型名不匹配”。
- 加入解析/嵌入/问答结果缓存与索引落盘（如 `outputs/index/`）。
- 增加“引用与页码”的证据返回（分块保留位置信息）。
- 复杂文档增强（OCR、表格/版面信息抽取；必要时引入 `unstructured`/`docling`）。
- 可观测性：请求链路日志、指标、失败样本留存；离线评测集与自动评估。

### 推荐迭代路径（务实落地）

- 第1周（MVP）
  - 植入向量库（FAISS/Chroma），新增 `RetrievalAgent`、`RerankAgent`，改造 `QA_Agent` 为 RAG。
  - 分块与元数据（页码、标题、文档名）完善；答案携带引用与页码。
  - 统一 LLM 默认为 Ollama（.env 可切换）；修复模型名一致性（避免 404）。
- 第2-3周
  - 表格解析与数值问题链路；Verifier 校验与重试；缓存策略（解析、嵌入、答案）。
  - 将 `DocumentAnalysisWorkflow` 接入 UI，支持单文档/多文档工作流选择。
- 第4周+
  - 多文档综合分析、报告生成；异步后台任务；评测与优化（RAGAS/对比评测）。
  - 复杂文档（OCR/版面）增强；高阶提示与自一致。

### 可以直接落地的改造清单（不展开代码）

- 新增：`agents/retrieval_agent.py`、`agents/rerank_agent.py`、`index/` 管理模块。
- 扩展：`document_parser` 返回分块与位置信息；`QA_Agent` 接收检索片段而非全文。
- 配置：`.env` 固化 `OLLAMA_MODEL=llama3.2:latest`（或实际存在的模型），统一默认提供商。
- UI：在侧边栏提供“工作流模式”（简化/标准RAG/多文档）。
- 存储：`uploads/`+`outputs/index/`（索引落盘）；缓存键=文档hash+分块策略+模型版本。
- 监控：请求耗时、命中率、引用覆盖率、失败重试次数；导出 CSV/JSON。

以上方案在你现有的 `BaseWorkflow`/`DocumentAnalysisWorkflow` 基础上就能快速对接，优先把检索、重排、引用、缓存落稳，质量与效率会立竿见影提升。
