# 智能文档分析系统 - 开发文档

## 项目概述

智能文档分析系统是一个基于MCP (Model Context Protocol) 和多智能体架构的文档分析平台，支持处理常见办公文档格式(.doc, .docx, .pptx, .xlsx, .pdf)，提供文档问答和数据分析功能。

### 核心特性
- 📄 **多格式文档支持**: 支持Word、PowerPoint、Excel、PDF等主流办公文档
- 🤖 **智能问答**: 基于文档内容的智能问答系统
- 📊 **数据分析**: 自动提取和分析文档中的数据
- 🔄 **工作流引擎**: 灵活的文档处理工作流
- 🌐 **Web界面**: 基于Streamlit的友好用户界面
- 🔌 **MCP架构**: 可扩展的微服务架构

## 技术架构

### 架构图
```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Web 界面      │    │   智能体层      │    │   MCP 服务层    │
│  (Streamlit)    │◄──►│   (Agents)      │◄──►│  (Services)     │
└─────────────────┘    └─────────────────┘    └─────────────────┘
         │                       │                       │
         │                       │                       │
         ▼                       ▼                       ▼
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   工作流引擎    │    │   工具层        │    │   存储层        │
│  (Workflows)    │    │   (Utils)       │    │ (Files/DB)      │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

### 核心组件

#### 1. MCP服务层 (`mcp_services/`)
- **BaseMCPService**: MCP服务基类，定义标准接口
- **DocumentParserService**: 文档解析服务，支持多种格式
- **FileOperationsService**: 文件操作服务，处理文件读写

#### 2. 智能体层 (`agents/`)
- **BaseAgent**: 智能体基类，定义智能体标准接口
- **QAAgent**: 问答智能体，处理文档问答任务
- **AnalysisAgent**: 分析智能体，进行数据分析

#### 3. 工作流引擎 (`workflows/`)
- **BaseWorkflow**: 工作流基类
- **DocumentWorkflow**: 文档处理工作流，端到端处理流程

#### 4. 工具层 (`utils/`)
- **llm_utils**: 大语言模型工具，支持多种LLM提供商
- **file_utils**: 文件处理工具
- **data_utils**: 数据处理工具

## 项目结构

```
document_analysis_system/
├── app.py                  # 主应用入口
├── requirements.txt        # 依赖包列表
├── start.bat              # Windows启动脚本
├── start.sh               # Linux/Mac启动脚本
├── README.md              # 项目说明
├── 开发文档.md            # 开发文档(本文档)
├── .env                   # 环境变量配置
│
├── config/                # 配置模块
│   ├── __init__.py
│   └── settings.py        # 系统配置
│
├── mcp_services/          # MCP服务模块
│   ├── __init__.py
│   ├── base_service.py    # MCP基础服务类
│   ├── document_parser.py # 文档解析服务
│   └── file_operations.py # 文件操作服务
│
├── agents/                # 智能体模块
│   ├── __init__.py
│   ├── base_agent.py      # 智能体基类
│   ├── qa_agent.py        # 问答智能体
│   └── analysis_agent.py  # 分析智能体
│
├── workflows/             # 工作流模块
│   ├── __init__.py
│   ├── base_workflow.py   # 工作流基类
│   └── document_workflow.py # 文档处理工作流
│
├── utils/                 # 工具模块
│   ├── __init__.py
│   ├── file_utils.py      # 文件处理工具
│   ├── llm_utils.py       # 大语言模型工具
│   └── data_utils.py      # 数据处理工具
│
├── docs/                  # 文档目录
│   └── third_party_api_guide.md # 第三方API使用指南
│
├── uploads/               # 上传文件目录
├── outputs/               # 输出文件目录
└── temp/                  # 临时文件目录
```

## 环境配置

### 1. 环境变量配置 (`.env`)

```bash
# LLM配置
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b
OLLAMA_TIMEOUT=120

# OpenAI配置 (可选)
OPENAI_API_KEY=your_openai_api_key
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MAX_TOKENS=4000

# 第三方API转发配置 (可选)
THIRD_PARTY_API_ENABLED=false
THIRD_PARTY_API_KEY=your_third_party_api_key
THIRD_PARTY_BASE_URL=https://your-proxy-service.com/v1

# 应用配置
APP_DEBUG=false
LOG_LEVEL=INFO
MAX_FILE_SIZE=50MB
SUPPORTED_FORMATS=docx,pptx,xlsx,pdf
```

### 2. 依赖包安装

```bash
pip install -r requirements.txt
```

### 主要依赖包说明:
- `streamlit`: Web界面框架
- `python-docx`: Word文档处理
- `python-pptx`: PowerPoint文档处理
- `openpyxl`: Excel文档处理
- `PyPDF2/pdfplumber`: PDF文档处理
- `ollama`: 本地LLM支持
- `openai`: OpenAI API支持
- `pandas/numpy`: 数据分析
- `fastapi/uvicorn`: API服务支持

## 核心模块详解

### 1. 配置系统 (`config/settings.py`)

配置系统采用环境变量驱动的方式，支持多种LLM提供商和第三方API转发。

**主要配置项:**
```python
# Ollama本地模型配置
OLLAMA_CONFIG = {
    "host": "http://localhost:11434",
    "model": "llama3.2:3b",
    "timeout": 120
}

# OpenAI配置
OPENAI_CONFIG = {
    "api_key": "your_api_key",
    "model": "gpt-3.5-turbo",
    "base_url": "https://api.openai.com/v1"
}
```

### 2. MCP服务系统

#### BaseMCPService 基类
提供MCP服务的标准接口和实现框架:

```python
class BaseMCPService(ABC):
    @abstractmethod
    async def handle_request(self, request: MCPRequest) -> MCPResponse:
        """处理MCP请求的抽象方法"""
        pass
```

#### DocumentParserService 文档解析服务
- 支持多种文档格式: DOCX, PPTX, XLSX, PDF
- 提供统一的文档解析接口
- 自动格式检测和内容提取

### 3. 智能体系统

#### BaseAgent 基类
定义智能体的标准接口和基础功能:

```python
class BaseAgent(ABC):
    @abstractmethod
    async def process(self, input_data: Any, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """处理输入数据的抽象方法"""
        pass
```

#### QAAgent 问答智能体
- 基于文档内容进行智能问答
- 支持上下文理解和多轮对话
- 提供准确性评估和置信度

#### AnalysisAgent 分析智能体
- 自动分析文档数据
- 生成数据洞察和报告
- 支持多种分析类型

### 4. 工作流引擎

#### BaseWorkflow 基类
提供工作流的标准框架:

```python
class BaseWorkflow(ABC):
    @abstractmethod
    async def execute(self, input_data: Any) -> Dict[str, Any]:
        """执行工作流的抽象方法"""
        pass
```

#### DocumentWorkflow 文档处理工作流
实现完整的文档处理流程:
1. 文档上传和验证
2. 格式检测和解析
3. 内容提取和预处理
4. 智能体处理
5. 结果输出和存储

### 5. LLM工具系统 (`utils/llm_utils.py`)

LLM管理器提供统一的大语言模型接口:

```python
class LLMManager:
    async def chat_completion(self, messages: List[Dict], provider: str = "ollama") -> str:
        """统一的聊天完成接口"""
        pass
```

支持的LLM提供商:
- **Ollama**: 本地模型支持
- **OpenAI**: OpenAI API
- **第三方转发**: 支持各种API转发服务

## 开发指南

### 1. 新增文档格式支持

要添加新的文档格式支持，需要在`DocumentParserService`中添加对应的解析器:

```python
class DocumentParserService(BaseMCPService):
    async def _parse_new_format(self, file_path: str) -> Dict[str, Any]:
        """解析新格式文档"""
        # 实现新格式的解析逻辑
        pass
```

### 2. 新增智能体类型

创建新的智能体需要继承`BaseAgent`:

```python
class CustomAgent(BaseAgent):
    async def process(self, input_data: Any, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """自定义处理逻辑"""
        # 实现具体的处理逻辑
        pass
```

### 3. 自定义工作流

创建自定义工作流需要继承`BaseWorkflow`:

```python
class CustomWorkflow(BaseWorkflow):
    async def execute(self, input_data: Any) -> Dict[str, Any]:
        """自定义工作流执行逻辑"""
        # 实现工作流步骤
        pass
```

### 4. 新增LLM提供商

在`llm_utils.py`中添加新的LLM提供商支持:

```python
class LLMManager:
    async def _call_custom_provider(self, messages: List[Dict], **kwargs) -> str:
        """自定义LLM提供商接口"""
        # 实现自定义提供商的API调用
        pass
```

## API接口

### 1. 文档上传接口
```python
POST /api/upload
Content-Type: multipart/form-data

# 参数
file: 文档文件
format: 文档格式 (可选，自动检测)
```

### 2. 文档问答接口
```python
POST /api/qa
Content-Type: application/json

{
    "document_id": "document_uuid",
    "question": "用户问题",
    "context": "对话上下文"
}
```

### 3. 数据分析接口
```python
POST /api/analysis
Content-Type: application/json

{
    "document_id": "document_uuid",
    "analysis_type": "summary|statistics|insights",
    "options": {}
}
```

## 部署指南

### 1. 本地开发环境

```bash
# 1. 克隆项目
git clone <repository_url>
cd document_analysis_system

# 2. 创建虚拟环境
python -m venv venv
source venv/bin/activate  # Linux/Mac
# 或
venv\Scripts\activate     # Windows

# 3. 安装依赖
pip install -r requirements.txt

# 4. 配置环境变量
cp .env.example .env
# 编辑.env文件，配置必要的环境变量

# 5. 启动应用
streamlit run app.py
```

### 2. Docker部署

```dockerfile
# Dockerfile示例
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8501

CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

### 3. 生产环境部署

建议使用以下技术栈:
- **Web服务器**: Nginx (反向代理)
- **应用服务器**: Gunicorn + Streamlit
- **数据库**: PostgreSQL (可选)
- **缓存**: Redis (可选)
- **容器化**: Docker + Docker Compose

## 性能优化

### 1. 文档处理优化
- 实现文档缓存机制
- 使用异步处理大文件
- 分片处理超大文档

### 2. LLM调用优化
- 实现请求缓存
- 批量处理多个请求
- 智能选择最优模型

### 3. 内存优化
- 及时释放大文件内存
- 使用流式处理
- 实现垃圾回收策略

## 监控与日志

### 1. 日志配置
```python
# 配置示例
LOGGING_CONFIG = {
    "level": "INFO",
    "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    "handlers": ["console", "file"]
}
```

### 2. 性能监控
- 响应时间监控
- 内存使用监控
- 错误率统计
- LLM API调用统计

### 3. 错误处理
- 全局异常捕获
- 详细错误日志
- 用户友好的错误提示
- 自动重试机制

## 测试策略

### 1. 单元测试
- 各个模块的独立测试
- Mock外部依赖
- 覆盖率要求: >80%

### 2. 集成测试
- 端到端流程测试
- API接口测试
- 文档处理流程测试

### 3. 性能测试
- 大文件处理测试
- 并发用户测试
- 内存泄漏测试

## 安全considerations

### 1. 文件安全
- 文件类型验证
- 文件大小限制
- 恶意文件检测
- 安全的文件存储

### 2. API安全
- 请求频率限制
- 输入验证和清理
- 认证和授权
- HTTPS强制使用

### 3. 数据安全
- 敏感数据加密
- 文件自动清理
- 访问日志记录
- 数据备份策略

## 常见问题解决

### 1. 文档解析失败
```python
# 检查文件格式和完整性
# 增加更详细的错误日志
# 提供备用解析方案
```

### 2. LLM调用超时
```python
# 增加超时设置
# 实现重试机制
# 使用备用模型
```

### 3. 内存不足
```python
# 优化文档处理流程
# 实现分片处理
# 增加内存监控
```

## 版本更新日志

### v1.0.0 (当前版本)
- ✅ 基础MCP架构实现
- ✅ 多格式文档支持
- ✅ 智能问答功能
- ✅ 数据分析功能
- ✅ Web界面实现

### 计划中的功能
- 🔄 多语言支持
- 🔄 高级数据可视化
- 🔄 批量文档处理
- 🔄 用户管理系统
- 🔄 API认证系统

## 贡献指南

1. Fork项目仓库
2. 创建特性分支 (`git checkout -b feature/AmazingFeature`)
3. 提交更改 (`git commit -m 'Add some AmazingFeature'`)
4. 推送到分支 (`git push origin feature/AmazingFeature`)
5. 创建Pull Request

## 许可证

本项目采用MIT许可证 - 查看[LICENSE](LICENSE)文件了解详情。

## 联系方式

- 项目仓库: [GitHub Repository URL]
- 问题反馈: [Issues URL]
- 文档站点: [Documentation URL]

---

*最后更新时间: 2025年8月7日*
