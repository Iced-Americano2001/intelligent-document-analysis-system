import streamlit as st
import asyncio
from pathlib import Path
from typing import Dict, Any
import logging
import pandas as pd

# å°è¯•å¯¼å…¥nest_asyncioï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
try:
    import nest_asyncio
    # å®‰å…¨åœ°åº”ç”¨åµŒå¥—äº‹ä»¶å¾ªç¯æ”¯æŒ
    try:
        nest_asyncio.apply()
    except RuntimeError:
        # å¦‚æœå½“å‰çº¿ç¨‹æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œå…ˆåˆ›å»ºä¸€ä¸ª
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            nest_asyncio.apply(loop)
        except Exception:
            # å¦‚æœä»ç„¶å¤±è´¥ï¼Œå¿½ç•¥é”™è¯¯ç»§ç»­æ‰§è¡Œ
            pass
except ImportError:
    # å¦‚æœnest_asyncioä¸å¯ç”¨ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
    pass

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½æ–‡æ¡£é—®ç­”",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å¯¼å…¥ç³»ç»Ÿæ¨¡å—
try:
    from config.settings import get_config
    from mcp_services.base_service import mcp_manager, handle_mcp_request
    from mcp_services.document_parser import DocumentParserService
    # æš‚æ—¶æ³¨é‡Šæ‰æœ‰é—®é¢˜çš„file_operationsæ¨¡å—
    # from mcp_services.file_operations import FileOperationsService
    from agents.base_agent import agent_coordinator
    from agents.mcp_agent import MCPDocumentQAAgent
    from utils.llm_utils import llm_manager
    from ui.streaming_components import StreamingChatInterface, InteractiveElements
    from ui.status_manager import ConversationStatusManager, PerformanceMonitor
    from utils.rag_utils import (
        compute_file_id,
        build_or_load_index,
        retrieve_with_optional_rerank,
        build_context_from_chunks,
    )
except ImportError as e:
    st.error(f"æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    st.stop()

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆå§‹åŒ–æœåŠ¡
@st.cache_resource
def initialize_services():
    """åˆå§‹åŒ–MCPæœåŠ¡å’Œæ™ºèƒ½ä½“"""
    try:
        # åˆå§‹åŒ–MCPæœåŠ¡
        doc_parser_service = DocumentParserService()
        # æš‚æ—¶åªåˆå§‹åŒ–æ–‡æ¡£è§£ææœåŠ¡ï¼Œè·³è¿‡æœ‰é—®é¢˜çš„æ–‡ä»¶æ“ä½œæœåŠ¡
        mcp_manager.register_service(doc_parser_service)
        
        # ç›´æ¥è°ƒç”¨æœåŠ¡åˆå§‹åŒ–ï¼ˆä¸é€šè¿‡å¼‚æ­¥æ–¹å¼ï¼‰
        import asyncio
        
        # åˆ›å»ºä¸´æ—¶äº‹ä»¶å¾ªç¯æ¥åˆå§‹åŒ–æœåŠ¡
        try:
            # å°è¯•åœ¨å½“å‰çº¿ç¨‹åˆå§‹åŒ–
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # å¦‚æœå¾ªç¯æ­£åœ¨è¿è¡Œï¼Œåˆ›å»ºä»»åŠ¡
                future = asyncio.ensure_future(doc_parser_service.initialize())
            else:
                # å¦‚æœå¾ªç¯æœªè¿è¡Œï¼Œç›´æ¥è¿è¡Œ
                init_success = loop.run_until_complete(doc_parser_service.initialize())
        except RuntimeError:
            # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                init_success = loop.run_until_complete(doc_parser_service.initialize())
            finally:
                loop.close()
        
        # åˆå§‹åŒ–å¹¶æ³¨å†Œæ™ºèƒ½ä½“
        from agents.qa_agent import QAAgent
        from agents.analysis_agent import AnalysisAgent
        qa_agent = QAAgent()
        analysis_agent = AnalysisAgent()
        agent_coordinator.register_agent(qa_agent)
        agent_coordinator.register_agent(analysis_agent)
        
        logger.info("æ–‡æ¡£è§£ææœåŠ¡ã€æ•°æ®åˆ†ææœåŠ¡å’Œæ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")
        return True
    except Exception as e:
        logger.error(f"æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

@st.cache_resource
def initialize_mcp_agent():
    """åˆå§‹åŒ–MCPæ™ºèƒ½ä½“"""
    try:
        mcp_agent = MCPDocumentQAAgent()
        
        # åŒæ­¥é¢„åˆå§‹åŒ–æœ¬åœ°å·¥å…·ï¼ˆé¿å…ç¬¬ä¸€æ¬¡ä½¿ç”¨æ—¶çš„å¼‚æ­¥åˆå§‹åŒ–é—®é¢˜ï¼‰
        def _sync_pre_init():
            try:
                # åŒæ­¥åŠ è½½æœ¬åœ°å·¥å…·æ¨¡å—
                import tools
                import pkgutil
                import importlib
                from tools.base_tool import tool_registry
                from mcp_services.modern_mcp_server import mcp_server
                
                logger.info("å¼€å§‹é¢„åŠ è½½æœ¬åœ°å·¥å…·æ¨¡å—...")
                for _, name, _ in pkgutil.iter_modules(tools.__path__, tools.__name__ + "."):
                    try:
                        importlib.import_module(name)
                        logger.debug(f"é¢„åŠ è½½å·¥å…·æ¨¡å—: {name}")
                    except Exception as e:
                        logger.warning(f"é¢„åŠ è½½å·¥å…·æ¨¡å— {name} å¤±è´¥: {e}")
                
                # é¢„æ³¨å†Œæœ¬åœ°å·¥å…·åˆ°æ™ºèƒ½ä½“
                tools_in_registry = tool_registry.list_tools()
                for tool in tools_in_registry:
                    if hasattr(tool, 'definition'):
                        mcp_agent.available_tools.append(tool.definition)
                
                # æ·»åŠ final_answerå·¥å…·
                mcp_agent.available_tools.append(mcp_agent.final_answer_tool)
                
                logger.info(f"é¢„åˆå§‹åŒ–å®Œæˆï¼ŒåŠ è½½äº† {len(mcp_agent.available_tools)} ä¸ªæœ¬åœ°å·¥å…·")
                mcp_agent._local_tools_loaded = True
                return True
            except Exception as e:
                logger.warning(f"é¢„åˆå§‹åŒ–å¤±è´¥: {e}")
                mcp_agent._local_tools_loaded = False
                return False
        
        # æ‰§è¡ŒåŒæ­¥é¢„åˆå§‹åŒ–
        _sync_pre_init()
        
        logger.info("MCPæ™ºèƒ½ä½“åˆ›å»ºå®Œæˆï¼Œæœ¬åœ°å·¥å…·å·²é¢„åŠ è½½")
        return mcp_agent
    except Exception as e:
        logger.error(f"MCPæ™ºèƒ½ä½“åˆ›å»ºå¤±è´¥: {e}")
        return None

def run_async_in_streamlit(coro):
    """åœ¨Streamlitç¯å¢ƒä¸­å®‰å…¨è¿è¡Œå¼‚æ­¥ä»£ç """
    import threading
    
    try:
        # æ–¹æ³•1: ç›´æ¥è¿è¡Œï¼ˆå¦‚æœæ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼‰
        return asyncio.run(coro)
    except RuntimeError as e:
        if "cannot be called from a running event loop" in str(e):
            # æ–¹æ³•2: åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œ
            try:
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, coro)
                    return future.result()
            except Exception:
                # æ–¹æ³•3: åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
                try:
                    loop = asyncio.new_event_loop()
                    old_loop = None
                    try:
                        old_loop = asyncio.get_event_loop()
                    except RuntimeError:
                        pass
                    
                    asyncio.set_event_loop(loop)
                    try:
                        return loop.run_until_complete(coro)
                    finally:
                        loop.close()
                        if old_loop:
                            asyncio.set_event_loop(old_loop)
                except Exception as final_e:
                    logger.error(f"æ‰€æœ‰å¼‚æ­¥æ‰§è¡Œæ–¹æ³•éƒ½å¤±è´¥äº†: {final_e}")
                    raise RuntimeError(f"æ— æ³•æ‰§è¡Œå¼‚æ­¥æ“ä½œ: {final_e}")
        else:
            raise

def display_qa_results(result: Dict[str, Any]):
    """æ˜¾ç¤ºé—®ç­”ç»“æœ"""
    st.success("âœ… é—®ç­”å®Œæˆï¼")
    
    if "answer" in result:
        st.markdown("### ğŸ“ AIå›ç­”")
        st.markdown(result["answer"])
    
    # æ˜¾ç¤ºç›¸å…³æ®µè½ï¼ˆQA Agent è¿”å›çš„æ˜¯ relevant_passagesï¼‰
    if "relevant_passages" in result and result["relevant_passages"]:
        st.markdown("### ğŸ“– ç›¸å…³å¼•ç”¨")
        passages = result["relevant_passages"]
        if isinstance(passages, list):
            for i, passage in enumerate(passages, 1):
                st.info(f"**å¼•ç”¨ {i}**: {passage}")
        else:
            st.info(f"**ç›¸å…³å†…å®¹**: {passages}")
    
    # æ˜¾ç¤ºç½®ä¿¡åº¦
    if "confidence" in result:
        st.markdown("### ğŸ“Š ç½®ä¿¡åº¦åˆ†æ")
        confidence = result["confidence"]
        if isinstance(confidence, (int, float)):
            st.progress(float(confidence), text=f"ç½®ä¿¡åº¦: {confidence:.1%}")
        else:
            st.info(f"ç½®ä¿¡åº¦: {confidence}")
    
    # æ˜¾ç¤ºé¢å¤–ä¿¡æ¯
    if "content_length" in result:
        col1, col2 = st.columns(2)
        with col1:
            st.metric("æ–‡æ¡£é•¿åº¦", f"{result['content_length']:,} å­—ç¬¦")
        with col2:
            st.metric("å›ç­”é•¿åº¦", f"{result.get('answer_length', 0):,} å­—ç¬¦")

async def process_document_qa(uploaded_file, question, answer_style="detailed", include_quotes=True, confidence_threshold=0.7,
                            enable_advanced_confidence=False, use_rag=True, use_reranker=True, rag_top_k=12, rag_rerank_top_n=6):
    """å¤„ç†æ–‡æ¡£é—®ç­”"""
    try:
        # è¿›åº¦æŒ‡ç¤º
        progress_bar = st.progress(0, text="å¼€å§‹å¤„ç†é—®ç­”...")
        
        # ä¿å­˜æ–‡ä»¶
        file_config = get_config("file")
        upload_dir = Path(file_config.get("upload_dir", "uploads"))
        upload_dir.mkdir(exist_ok=True)
        
        file_path = upload_dir / uploaded_file.name
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        progress_bar.progress(25, text="ğŸ“ æ–‡æ¡£ä¿å­˜å®Œæˆ...")
        
        # è§£ææ–‡æ¡£
        progress_bar.progress(50, text="ğŸ“– æ­£åœ¨è§£ææ–‡æ¡£...")
        
        parse_result = await handle_mcp_request(
            method="document_parser/extract_text",
            params={"file_path": str(file_path)}
        )
        
        if parse_result.get("result", {}).get("success", False):
            text_content = parse_result["result"]["result"]["text_content"]
            
            # RAGå¤„ç†
            context_text = text_content
            if use_rag and text_content:
                try:
                    progress_bar.progress(60, text="ğŸ” æ„å»ºRAGç´¢å¼•...")
                    
                    # è®¡ç®—æ–‡ä»¶ID
                    file_id = compute_file_id(str(file_path))
                    
                    # æ„å»ºæˆ–åŠ è½½ç´¢å¼•
                    store, embedder, reranker = build_or_load_index(file_id, text_content)
                    
                    progress_bar.progress(70, text="ğŸ” RAGæ£€ç´¢ç›¸å…³å†…å®¹...")
                    
                    # æ£€ç´¢ç›¸å…³ç‰‡æ®µ
                    chunks = retrieve_with_optional_rerank(
                        query=question,
                        store=store,
                        embedder=embedder,
                        top_k=rag_top_k,
                        rerank_top_n=rag_rerank_top_n,
                        use_reranker=use_reranker
                    )
                    
                    if chunks:
                        # æ„å»ºä¸Šä¸‹æ–‡
                        context_text = build_context_from_chunks(chunks)
                        logger.info(f"RAGæ£€ç´¢åˆ°{len(chunks)}ä¸ªç›¸å…³ç‰‡æ®µ")
                    else:
                        logger.warning("RAGæœªæ£€ç´¢åˆ°ç›¸å…³ç‰‡æ®µï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬")
                        
                except Exception as e:
                    logger.error(f"RAGå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬: {e}")
                    # RAGå¤±è´¥æ—¶å›é€€åˆ°åŸå§‹æ–‡æœ¬
                    context_text = text_content
            
            progress_bar.progress(75, text="ğŸ¤– AIæ­£åœ¨æ€è€ƒç­”æ¡ˆ...")
            
            # æ‰§è¡Œé—®ç­”
            qa_input = {
                "document_content": context_text,
                "question": question,
                "document_type": Path(uploaded_file.name).suffix,
                "answer_style": answer_style,
                "include_quotes": include_quotes,
                "confidence_threshold": confidence_threshold,
                "use_rag": use_rag,
                "rag_chunks_count": len(chunks) if use_rag and 'chunks' in locals() else 0
            }
            
            qa_result = await agent_coordinator.execute_agent(
                "QA_Agent",
                qa_input
            )
            
            progress_bar.progress(100, text="âœ… é—®ç­”å®Œæˆï¼")
            
            if qa_result.get("success", False):
                display_qa_results(qa_result["result"])
            else:
                st.error(f"âŒ é—®ç­”å¤±è´¥: {qa_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                st.warning("ğŸ’¡ å»ºè®®é‡æ–°è¡¨è¿°é—®é¢˜æˆ–æ£€æŸ¥æ–‡æ¡£å†…å®¹")
        else:
            st.error("âŒ æ–‡æ¡£è§£æå¤±è´¥")
            st.warning("ğŸ’¡ è¯·æ£€æŸ¥æ–‡æ¡£æ ¼å¼æ˜¯å¦æ­£ç¡®")
            
    except Exception as e:
        st.error(f"âŒ é—®ç­”å¤„ç†å¤±è´¥: {str(e)}")
        st.warning("ğŸ’¡ å¦‚æœé—®é¢˜æŒç»­å­˜åœ¨ï¼Œè¯·å°è¯•ç®€åŒ–é—®é¢˜æˆ–æ›´æ¢æ–‡æ¡£")
        logger.error(f"é—®ç­”å¤„ç†å¤±è´¥: {e}")

async def process_mcp_qa(uploaded_file, question, mcp_agent, answer_style="detailed", 
                        include_quotes=True, confidence_threshold=0.7, max_iterations=10, show_thinking=True,
                        use_rag=True, use_reranker=True, rag_top_k=12, rag_rerank_top_n=6):
    """ä½¿ç”¨MCPæ™ºèƒ½ä½“å¤„ç†æ–‡æ¡£é—®ç­”"""
    try:
        # è¿›åº¦æŒ‡ç¤º
        status_manager = ConversationStatusManager()
        status_manager.start_conversation(max_iterations)
        
        performance_monitor = PerformanceMonitor()
        performance_monitor.start_monitoring()
        
        # ä¿å­˜æ–‡ä»¶
        file_config = get_config("file")
        upload_dir = Path(file_config.get("upload_dir", "uploads"))
        upload_dir.mkdir(exist_ok=True)
        
        file_path = upload_dir / uploaded_file.name
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        status_manager.update_step("thinking", "æ–‡æ¡£å·²ä¿å­˜ï¼Œå¼€å§‹è§£æ...")
        
        # è§£ææ–‡æ¡£
        parse_result = await handle_mcp_request(
            method="document_parser/extract_text",
            params={"file_path": str(file_path)}
        )
        
        if parse_result.get("result", {}).get("success", False):
            text_content = parse_result["result"]["result"]["text_content"]
            
            # RAGå¤„ç†
            context_text = text_content
            rag_chunks_info = {"enabled": False, "chunks_count": 0}
            
            if use_rag and text_content:
                try:
                    status_manager.update_step("thinking", "æ„å»ºRAGç´¢å¼•...")
                    
                    # è®¡ç®—æ–‡ä»¶ID
                    file_id = compute_file_id(str(file_path))
                    
                    # æ„å»ºæˆ–åŠ è½½ç´¢å¼•
                    store, embedder, reranker = build_or_load_index(file_id, text_content)
                    
                    status_manager.update_step("thinking", "RAGæ£€ç´¢ç›¸å…³å†…å®¹...")
                    
                    # æ£€ç´¢ç›¸å…³ç‰‡æ®µ
                    chunks = retrieve_with_optional_rerank(
                        query=question,
                        store=store,
                        embedder=embedder,
                        top_k=rag_top_k,
                        rerank_top_n=rag_rerank_top_n,
                        use_reranker=use_reranker
                    )
                    
                    if chunks:
                        # æ„å»ºä¸Šä¸‹æ–‡
                        context_text = build_context_from_chunks(chunks)
                        rag_chunks_info = {"enabled": True, "chunks_count": len(chunks)}
                        logger.info(f"RAGæ£€ç´¢åˆ°{len(chunks)}ä¸ªç›¸å…³ç‰‡æ®µ")
                        status_manager.update_step("thinking", f"RAGæ£€ç´¢å®Œæˆï¼Œè·å¾—{len(chunks)}ä¸ªç›¸å…³ç‰‡æ®µ")
                    else:
                        logger.warning("RAGæœªæ£€ç´¢åˆ°ç›¸å…³ç‰‡æ®µï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬")
                        status_manager.update_step("thinking", "RAGæœªæ£€ç´¢åˆ°ç›¸å…³ç‰‡æ®µï¼Œä½¿ç”¨åŸå§‹æ–‡æ¡£")
                        
                except Exception as e:
                    logger.error(f"RAGå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬: {e}")
                    status_manager.update_step("thinking", f"RAGå¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹æ–‡æ¡£: {str(e)}")
                    # RAGå¤±è´¥æ—¶å›é€€åˆ°åŸå§‹æ–‡æœ¬
                    context_text = text_content
            
            status_manager.update_step("thinking", "æ–‡æ¡£è§£æå®Œæˆï¼Œå¯åŠ¨MCPæ™ºèƒ½ä½“...")
            
            # è®¾ç½®æ™ºèƒ½ä½“å‚æ•°
            mcp_agent.max_iterations = max_iterations
            
            # å‡†å¤‡è¾“å…¥æ•°æ®
            qa_input = {
                "question": question,
                "document_content": context_text,
                "document_type": Path(uploaded_file.name).suffix,
                "document_file_path": str(file_path),
                "answer_style": answer_style,
                "include_quotes": include_quotes,
                "confidence_threshold": confidence_threshold,
                "rag_info": rag_chunks_info
            }
            
            # åˆ›å»ºæµå¼èŠå¤©ç•Œé¢
            if show_thinking:
                chat_interface = StreamingChatInterface()
                
                # æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹æµ - æ­£ç¡®ä¼ é€’å¼‚æ­¥ç”Ÿæˆå™¨
                logger.info("å¼€å§‹åˆ›å»ºMCPæ™ºèƒ½ä½“æ€è€ƒæµç¨‹")
                try:
                    # æ™ºèƒ½åˆå§‹åŒ–æ£€æŸ¥
                    if not mcp_agent.is_initialized():
                        logger.info("æ™ºèƒ½ä½“éœ€è¦åˆå§‹åŒ–...")
                        
                        # æ˜¾ç¤ºåˆå§‹åŒ–è¿›åº¦
                        with st.spinner("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–MCPæ™ºèƒ½ä½“..."):
                            await mcp_agent.ensure_initialized()
                        
                        st.success("âœ… MCPæ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")
                    else:
                        logger.info(f"æ™ºèƒ½ä½“å·²åˆå§‹åŒ–ï¼Œ{len(mcp_agent.available_tools)}ä¸ªå·¥å…·å¯ç”¨")
                    
                    # åœ¨èŠå¤©ç•Œé¢æ˜¾ç¤ºRAGä¿¡æ¯
                    if rag_chunks_info["enabled"]:
                        st.info(f"ğŸ” RAGå·²æ¿€æ´»ï¼Œæ£€ç´¢åˆ° {rag_chunks_info['chunks_count']} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ")
                    
                    # åˆ›å»ºå¼‚æ­¥ç”Ÿæˆå™¨
                    thought_generator = mcp_agent.think_and_act(
                        question,
                        context_text,  # ä½¿ç”¨RAGå¤„ç†åçš„å†…å®¹
                        Path(uploaded_file.name).suffix,
                        str(file_path)
                    )
                    logger.info(f"æ€è€ƒç”Ÿæˆå™¨åˆ›å»ºæˆåŠŸ: {type(thought_generator)}")
                    
                    # æ˜¾ç¤ºæ€è€ƒæµç¨‹
                    final_answer = await chat_interface.display_thought_stream(thought_generator)
                    logger.info(f"æ€è€ƒæµç¨‹å®Œæˆï¼Œæœ€ç»ˆç­”æ¡ˆé•¿åº¦: {len(final_answer) if final_answer else 0}")
                    
                except Exception as e:
                    logger.error(f"MCPæ€è€ƒæµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
                    import traceback
                    logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                    st.error(f"âŒ MCPæ™ºèƒ½ä½“æ‰§è¡Œå¤±è´¥: {str(e)}")
                    return
                
                status_manager.complete_conversation(True)
                performance_monitor.end_monitoring()
                
                # æ˜¾ç¤ºæ€§èƒ½æŠ¥å‘Š
                with st.expander("ğŸ“Š æ‰§è¡Œæ€§èƒ½æŠ¥å‘Š", expanded=False):
                    performance_monitor.show_performance_report()
                
                # æ˜¾ç¤ºçŠ¶æ€å†å²
                with st.expander("ğŸ“‹ è¯¦ç»†æ‰§è¡Œå†å²", expanded=False):
                    status_manager.show_status_history()
            
            else:
                # ä¸æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ï¼Œç›´æ¥å¤„ç†
                with st.spinner("ğŸ§  MCPæ™ºèƒ½ä½“æ­£åœ¨æ·±åº¦æ€è€ƒ..."):
                    # åœ¨ç®€åŒ–æ¨¡å¼ä¸‹ä¹Ÿæ˜¾ç¤ºRAGä¿¡æ¯
                    if rag_chunks_info["enabled"]:
                        st.info(f"ğŸ” RAGå·²æ¿€æ´»ï¼Œæ£€ç´¢åˆ° {rag_chunks_info['chunks_count']} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ")
                    
                    result = await mcp_agent.process(qa_input)
                    
                    if result.get("answer"):
                        st.markdown("### ğŸ¯ æœ€ç»ˆç­”æ¡ˆ")
                        st.write(result["answer"])
                        
                        # æ˜¾ç¤ºç®€åŒ–çš„ç»“æœä¿¡æ¯
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("æ€è€ƒè½®æ•°", result.get("iterations_used", 0))
                        with col2:
                            st.metric("å¯ç”¨å·¥å…·", result.get("tools_available", 0))
                        with col3:
                            st.metric("æ€è€ƒæ­¥éª¤", len(result.get("thought_processes", [])))
                
        else:
            st.error("âŒ æ–‡æ¡£è§£æå¤±è´¥")
            status_manager.complete_conversation(False)
            st.warning("ğŸ’¡ è¯·æ£€æŸ¥æ–‡æ¡£æ ¼å¼æ˜¯å¦æ­£ç¡®")
            
    except Exception as e:
        st.error(f"âŒ MCPé—®ç­”å¤„ç†å¤±è´¥: {str(e)}")
        st.warning("ğŸ’¡ å¦‚æœé—®é¢˜æŒç»­å­˜åœ¨ï¼Œè¯·å°è¯•ç®€åŒ–é—®é¢˜æˆ–åˆ‡æ¢åˆ°ä¼ ç»Ÿé—®ç­”æ¨¡å¼")
        logger.error(f"MCPé—®ç­”å¤„ç†å¤±è´¥: {e}")
        
        if 'status_manager' in locals():
            status_manager.complete_conversation(False)

async def process_mcp_data_analysis(uploaded_file, analysis_requirements, mcp_agent, 
                                   max_iterations=10, show_thinking=True, confidence_threshold=0.7,
                                   use_rag=True, use_reranker=True, rag_top_k=12, rag_rerank_top_n=6):
    """ä½¿ç”¨MCPæ™ºèƒ½ä½“å¤„ç†æ•°æ®åˆ†æ"""
    try:
        # è¿›åº¦æŒ‡ç¤º
        status_manager = ConversationStatusManager()
        status_manager.start_conversation(max_iterations)
        
        performance_monitor = PerformanceMonitor()
        performance_monitor.start_monitoring()
        
        # ä¿å­˜æ–‡ä»¶
        file_config = get_config("file")
        upload_dir = Path(file_config.get("upload_dir", "uploads"))
        upload_dir.mkdir(exist_ok=True)
        
        file_path = upload_dir / uploaded_file.name
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        status_manager.update_step("thinking", "æ•°æ®æ–‡ä»¶å·²ä¿å­˜ï¼Œå¼€å§‹è§£æ...")
        
        # è¯»å–æ•°æ®
        try:
            df = pd.read_excel(file_path)
            data_json = df.to_json(orient='records', date_format='iso')
            
            # ä¸ºæ•°æ®åˆ†æåˆ›å»ºå¯è¯»çš„æ–‡æœ¬è¡¨ç¤º
            data_summary = f"""
æ•°æ®æ¦‚è§ˆ:
- æ€»è¡Œæ•°: {df.shape[0]}
- æ€»åˆ—æ•°: {df.shape[1]}
- åˆ—å: {', '.join(df.columns.tolist())}

æ•°æ®æ ·æœ¬ (å‰5è¡Œ):
{df.head().to_string()}

æ•°æ®ç»Ÿè®¡ä¿¡æ¯:
{df.describe().to_string()}
"""
            
            status_manager.update_step("thinking", f"æ•°æ®è§£æå®Œæˆï¼Œ{df.shape[0]}è¡Œ{df.shape[1]}åˆ—")
            
        except Exception as e:
            st.error(f"âŒ æ•°æ®è§£æå¤±è´¥: {str(e)}")
            status_manager.complete_conversation(False)
            return
        
        # RAGå¤„ç† - å¯¹äºæ•°æ®åˆ†æï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æ•°æ®æ‘˜è¦å’Œåˆ†æéœ€æ±‚è¿›è¡ŒRAGå¤„ç†
        context_text = data_json
        rag_chunks_info = {"enabled": False, "chunks_count": 0}
        
        if use_rag and len(data_summary) > 1000:  # åªæœ‰å½“æ•°æ®æ‘˜è¦è¶³å¤Ÿé•¿æ—¶æ‰ä½¿ç”¨RAG
            try:
                status_manager.update_step("thinking", "æ„å»ºæ•°æ®RAGç´¢å¼•...")
                
                # è®¡ç®—æ–‡ä»¶ID
                file_id = compute_file_id(str(file_path) + "_data_analysis")
                
                # ä½¿ç”¨æ•°æ®æ‘˜è¦æ„å»ºç´¢å¼•
                store, embedder, reranker = build_or_load_index(file_id, data_summary)
                
                status_manager.update_step("thinking", "RAGæ£€ç´¢ç›¸å…³æ•°æ®ä¿¡æ¯...")
                
                # æ£€ç´¢ç›¸å…³ç‰‡æ®µ
                chunks = retrieve_with_optional_rerank(
                    query=analysis_requirements,
                    store=store,
                    embedder=embedder,
                    top_k=rag_top_k,
                    rerank_top_n=rag_rerank_top_n,
                    use_reranker=use_reranker
                )
                
                if chunks:
                    # æ„å»ºä¸Šä¸‹æ–‡ï¼Œä½†ä»ä¿ç•™åŸå§‹JSONæ•°æ®
                    context_summary = build_context_from_chunks(chunks)
                    # åˆå¹¶RAGæ£€ç´¢çš„ä¸Šä¸‹æ–‡å’ŒåŸå§‹æ•°æ®
                    context_text = f"æ•°æ®ä¸Šä¸‹æ–‡:\n{context_summary}\n\nåŸå§‹æ•°æ®:\n{data_json}"
                    rag_chunks_info = {"enabled": True, "chunks_count": len(chunks)}
                    logger.info(f"æ•°æ®åˆ†æRAGæ£€ç´¢åˆ°{len(chunks)}ä¸ªç›¸å…³ç‰‡æ®µ")
                    status_manager.update_step("thinking", f"RAGæ£€ç´¢å®Œæˆï¼Œè·å¾—{len(chunks)}ä¸ªç›¸å…³æ•°æ®ç‰‡æ®µ")
                else:
                    logger.warning("æ•°æ®åˆ†æRAGæœªæ£€ç´¢åˆ°ç›¸å…³ç‰‡æ®µï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
                    status_manager.update_step("thinking", "RAGæœªæ£€ç´¢åˆ°ç›¸å…³ç‰‡æ®µï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
                    
            except Exception as e:
                logger.error(f"æ•°æ®åˆ†æRAGå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®: {e}")
                status_manager.update_step("thinking", f"RAGå¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹æ•°æ®: {str(e)}")
                # RAGå¤±è´¥æ—¶å›é€€åˆ°åŸå§‹æ•°æ®
                context_text = data_json
        
        status_manager.update_step("thinking", "å¼€å§‹MCPæ™ºèƒ½ä½“åˆ†æ...")
        
        # è®¾ç½®æ™ºèƒ½ä½“å‚æ•°
        mcp_agent.max_iterations = max_iterations
        
        # åˆ›å»ºæµå¼èŠå¤©ç•Œé¢
        if show_thinking:
            chat_interface = StreamingChatInterface()
            
            # æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹æµ
            logger.info("å¼€å§‹åˆ›å»ºMCPæ™ºèƒ½ä½“æ•°æ®åˆ†ææµç¨‹")
            try:
                # æ™ºèƒ½åˆå§‹åŒ–æ£€æŸ¥
                if not mcp_agent.is_initialized():
                    logger.info("æ™ºèƒ½ä½“éœ€è¦åˆå§‹åŒ–...")
                    
                    # æ˜¾ç¤ºåˆå§‹åŒ–è¿›åº¦
                    with st.spinner("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–MCPæ™ºèƒ½ä½“..."):
                        await mcp_agent.ensure_initialized()
                    
                    st.success("âœ… MCPæ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")
                else:
                    logger.info(f"æ™ºèƒ½ä½“å·²åˆå§‹åŒ–ï¼Œ{len(mcp_agent.available_tools)}ä¸ªå·¥å…·å¯ç”¨")
                
                # åœ¨èŠå¤©ç•Œé¢æ˜¾ç¤ºæ•°æ®å’ŒRAGä¿¡æ¯
                st.info(f"ğŸ“Š æ•°æ®å·²åŠ è½½: {df.shape[0]}è¡Œ Ã— {df.shape[1]}åˆ—")
                if rag_chunks_info["enabled"]:
                    st.info(f"ğŸ” RAGå·²æ¿€æ´»ï¼Œæ£€ç´¢åˆ° {rag_chunks_info['chunks_count']} ä¸ªç›¸å…³æ•°æ®ç‰‡æ®µ")
                
                # åˆ›å»ºå¼‚æ­¥ç”Ÿæˆå™¨ - ä½¿ç”¨RAGå¤„ç†åçš„æ•°æ®å†…å®¹
                thought_generator = mcp_agent.think_and_act(
                    analysis_requirements,
                    context_text,  # ä¼ é€’RAGå¤„ç†åçš„æ•°æ®å†…å®¹
                    Path(uploaded_file.name).suffix,
                    str(file_path)
                )
                logger.info(f"æ•°æ®åˆ†ææ€è€ƒç”Ÿæˆå™¨åˆ›å»ºæˆåŠŸ: {type(thought_generator)}")
                
                # æ˜¾ç¤ºæ€è€ƒæµç¨‹
                final_answer = await chat_interface.display_thought_stream(thought_generator)
                logger.info(f"æ•°æ®åˆ†ææ€è€ƒæµç¨‹å®Œæˆï¼Œæœ€ç»ˆç­”æ¡ˆé•¿åº¦: {len(final_answer) if final_answer else 0}")
                
            except Exception as e:
                logger.error(f"MCPæ•°æ®åˆ†ææ€è€ƒæµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
                import traceback
                logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                st.error(f"âŒ MCPæ™ºèƒ½ä½“æ•°æ®åˆ†ææ‰§è¡Œå¤±è´¥: {str(e)}")
                return
            
            status_manager.complete_conversation(True)
            performance_monitor.end_monitoring()
            
            # æ˜¾ç¤ºæ€§èƒ½æŠ¥å‘Š
            with st.expander("ğŸ“Š æ‰§è¡Œæ€§èƒ½æŠ¥å‘Š", expanded=False):
                performance_monitor.show_performance_report()
            
            # æ˜¾ç¤ºçŠ¶æ€å†å²
            with st.expander("ğŸ“‹ è¯¦ç»†æ‰§è¡Œå†å²", expanded=False):
                status_manager.show_status_history()
        
        else:
            # ä¸æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ï¼Œç›´æ¥å¤„ç†
            with st.spinner("ğŸ§  MCPæ™ºèƒ½ä½“æ­£åœ¨æ·±åº¦åˆ†ææ•°æ®..."):
                # åœ¨ç®€åŒ–æ¨¡å¼ä¸‹ä¹Ÿæ˜¾ç¤ºæ•°æ®å’ŒRAGä¿¡æ¯
                st.info(f"ğŸ“Š æ•°æ®å·²åŠ è½½: {df.shape[0]}è¡Œ Ã— {df.shape[1]}åˆ—")
                if rag_chunks_info["enabled"]:
                    st.info(f"ğŸ” RAGå·²æ¿€æ´»ï¼Œæ£€ç´¢åˆ° {rag_chunks_info['chunks_count']} ä¸ªç›¸å…³æ•°æ®ç‰‡æ®µ")
                
                # è¿™é‡Œå¯ä»¥è°ƒç”¨mcp_agentçš„åŒæ­¥æ–¹æ³•ï¼Œä½†ç›®å‰ä½¿ç”¨think_and_actå¹¶å¿½ç•¥æµ
                result = await mcp_agent.process({
                    "question": analysis_requirements,
                    "document_content": context_text,
                    "document_type": Path(uploaded_file.name).suffix,
                    "document_file_path": str(file_path),
                    "confidence_threshold": confidence_threshold,
                    "rag_info": rag_chunks_info
                })
                
                if result.get("answer"):
                    st.markdown("### ğŸ¯ æ•°æ®åˆ†æç»“æœ")
                    st.write(result["answer"])
                    
                    # æ˜¾ç¤ºç®€åŒ–çš„ç»“æœä¿¡æ¯
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("æ€è€ƒè½®æ•°", result.get("iterations_used", 0))
                    with col2:
                        st.metric("å¯ç”¨å·¥å…·", result.get("tools_available", 0))
                    with col3:
                        st.metric("æ€è€ƒæ­¥éª¤", len(result.get("thought_processes", [])))
    
    except Exception as e:
        st.error(f"âŒ MCPæ•°æ®åˆ†æå¤„ç†å¤±è´¥: {str(e)}")
        st.warning("ğŸ’¡ å¦‚æœé—®é¢˜æŒç»­å­˜åœ¨ï¼Œè¯·å°è¯•ç®€åŒ–åˆ†æè¦æ±‚æˆ–æ£€æŸ¥æ•°æ®æ ¼å¼")
        logger.error(f"MCPæ•°æ®åˆ†æå¤„ç†å¤±è´¥: {e}")
        
        if 'status_manager' in locals():
            status_manager.complete_conversation(False)

def display_analysis_results(result: Dict[str, Any]):
    """æ˜¾ç¤ºæ•°æ®åˆ†æç»“æœ"""
    st.success("âœ… æ•°æ®åˆ†æå®Œæˆï¼")

    # 1. AI æ•°æ®åˆ†æ
    if "ai_insights" in result:
        st.markdown("### ğŸ¤– AI æ•°æ®åˆ†æ")
        st.info(result["ai_insights"])

    # 2. ä¸šåŠ¡å»ºè®®
    if "recommendations" in result and result["recommendations"]:
        with st.expander("ğŸ“ˆ ä¸šåŠ¡å»ºè®®ä¸è¡ŒåŠ¨æŒ‡å—", expanded=True):
            for rec in result["recommendations"]:
                st.markdown(f"- {rec}")
    
    # 3. å¯è§†åŒ–å›¾è¡¨
    if "visualizations" in result and result["visualizations"]:
        st.markdown("### ğŸ¨ äº¤äº’å¼å¯è§†åŒ–å›¾è¡¨")
        for title, fig in result["visualizations"].items():
            if fig: # ç¡®ä¿å›¾è¡¨å¯¹è±¡å­˜åœ¨
                st.plotly_chart(fig, use_container_width=True)

    # 4. æ•°æ®æ‘˜è¦
    with st.expander("ğŸ“Š æ•°æ®æ‘˜è¦ä¸ç»Ÿè®¡"):
        if "data_summary" in result:
            summary = result["data_summary"]
            basic_info = summary.get("åŸºæœ¬ä¿¡æ¯", {})
            cols = st.columns(4)
            cols[0].metric("æ•°æ®è¡Œæ•°", basic_info.get('è¡Œæ•°', 'N/A'))
            cols[1].metric("æ•°æ®åˆ—æ•°", basic_info.get('åˆ—æ•°', 'N/A'))
            cols[2].metric("å†…å­˜å ç”¨", basic_info.get('å†…å­˜å ç”¨', 'N/A'))
            cols[3].metric("æ•°æ®æº", basic_info.get('æ•°æ®æº', 'N/A'))
            
            if "åˆ—ä¿¡æ¯" in summary:
                st.markdown("#### åˆ—ä¿¡æ¯æ¦‚è§ˆ")
                # å°†åˆ—ä¿¡æ¯è½¬æ¢ä¸ºDataFrameä»¥ä¾¿æ›´å¥½åœ°æ˜¾ç¤º
                col_df = pd.DataFrame(summary["åˆ—ä¿¡æ¯"]).T
                st.dataframe(col_df)

        if "statistical_analysis" in result and result["statistical_analysis"].get("descriptive"):
             st.markdown("#### æè¿°æ€§ç»Ÿè®¡")
             st.dataframe(pd.DataFrame(result["statistical_analysis"]["descriptive"]))


async def process_data_analysis(uploaded_file, analysis_type, requirements, trend_params):
    """å¤„ç†æ•°æ®åˆ†æ"""
    progress_bar = st.progress(0, text="å¼€å§‹æ•°æ®åˆ†æ...")
    try:
        try:
            df = pd.read_excel(uploaded_file)
        except Exception as e:
            st.error(f"æ— æ³•è¯»å–æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚é”™è¯¯: {e}")
            return
        
        progress_bar.progress(25, text="ğŸ“„ æ•°æ®åŠ è½½å®Œæˆ...")

        analysis_input = {
            "data": df,
            "analysis_type": analysis_type,
            "requirements": requirements,
            "source": uploaded_file.name,
            **trend_params # åˆå¹¶è¶‹åŠ¿åˆ†æå‚æ•°
        }
        progress_bar.progress(50, text="ğŸ¤– AIæ­£åœ¨è¿›è¡Œæ•°æ®åˆ†æ...")

        analysis_result = await agent_coordinator.execute_agent("Analysis_Agent", analysis_input)
        progress_bar.progress(100, text="âœ… åˆ†æå®Œæˆï¼")
        
        if analysis_result.get("success", False):
            display_analysis_results(analysis_result["result"])
        else:
            st.error(f"âŒ æ•°æ®åˆ†æå¤±è´¥: {analysis_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    except Exception as e:
        st.error(f"âŒ æ•°æ®åˆ†æå¤„ç†å¤±è´¥: {str(e)}")
        logger.error(f"æ•°æ®åˆ†æå¤„ç†å¤±è´¥: {e}", exc_info=True)

def main():
    st.title("ğŸ¤– æ™ºèƒ½æ–‡æ¡£åˆ†æç³»ç»Ÿ")
    st.write("ä¸Šä¼ æ–‡æ¡£åï¼Œæ‚¨å¯ä»¥ç”¨è‡ªç„¶è¯­è¨€æé—®ï¼ŒAIåŠ©æ‰‹å°†åŸºäºæ–‡æ¡£å†…å®¹ä¸ºæ‚¨æä¾›å‡†ç¡®ç­”æ¡ˆã€‚")
    
    # ä¾§è¾¹æ  - Agenté€‰æ‹©
    st.sidebar.title("âš™ï¸ ç³»ç»Ÿè®¾ç½®")
    st.sidebar.markdown("---")
    
    # Agentç±»å‹é€‰æ‹©
    agent_type = st.sidebar.selectbox(
        "ğŸ¤– é€‰æ‹©AIåŠ©æ‰‹ç±»å‹",
        options=["ä¼ ç»Ÿé—®ç­”", "MCPæ™ºèƒ½åŠ©æ‰‹"],
        index=1,  # é»˜è®¤é€‰æ‹©MCP
        help="ä¼ ç»Ÿé—®ç­”ï¼šå¿«é€Ÿç®€å•é—®ç­”\nMCPæ™ºèƒ½åŠ©æ‰‹ï¼šå…·å¤‡å·¥å…·è°ƒç”¨å’Œæ·±åº¦æ€è€ƒèƒ½åŠ›"
    )
    
    # æ˜¾ç¤ºAgentç‰¹æ€§
    if agent_type == "ä¼ ç»Ÿé—®ç­”":
        st.sidebar.info("""
        **ç‰¹ç‚¹**:
        â€¢ âš¡ å¿«é€Ÿå“åº”
        â€¢ ğŸ“ ç›´æ¥é—®ç­”
        â€¢ ğŸ¯ ç®€æ´å‡†ç¡®
        """)
    else:
        st.sidebar.success("""
        **ç‰¹ç‚¹**:
        â€¢ ğŸ§  æ·±åº¦æ€è€ƒ
        â€¢ ğŸ”§ å·¥å…·è°ƒç”¨
        â€¢ ğŸ”„ å¤šè½®æ¨ç†
        â€¢ ğŸ“Š æµç¨‹é€æ˜
        """)
    
    st.sidebar.markdown("---")
    st.sidebar.write("å½“å‰ç‰ˆæœ¬: v3.0.0")
    
    # åˆå§‹åŒ–æœåŠ¡
    if not initialize_services():
        st.error("ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
        st.stop()

    # å¦‚æœé€‰æ‹©MCPæ™ºèƒ½ä½“ï¼Œåˆå§‹åŒ–MCPæœåŠ¡
    mcp_agent = None
    if agent_type == "MCPæ™ºèƒ½åŠ©æ‰‹":
        mcp_agent = initialize_mcp_agent()
        if mcp_agent is None:
            st.warning("MCPæ™ºèƒ½ä½“åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿé—®ç­”æ¨¡å¼")
            agent_type = "ä¼ ç»Ÿé—®ç­”"

    # åˆå§‹åŒ–tabçŠ¶æ€
    if 'active_tab' not in st.session_state:
        st.session_state.active_tab = "ğŸ¤– æ™ºèƒ½æ–‡æ¡£é—®ç­”"

    # ä½¿ç”¨radioæŒ‰é’®æ›¿ä»£tabsæ¥æ›´å¥½åœ°æ§åˆ¶çŠ¶æ€
    active_tab = st.radio(
        "é€‰æ‹©åŠŸèƒ½",
        ["ğŸ¤– æ™ºèƒ½æ–‡æ¡£é—®ç­”", "ğŸ“Š æ™ºèƒ½æ•°æ®åˆ†æ"],
        index=["ğŸ¤– æ™ºèƒ½æ–‡æ¡£é—®ç­”", "ğŸ“Š æ™ºèƒ½æ•°æ®åˆ†æ"].index(st.session_state.active_tab),
        horizontal=True,
        key="main_tab_selector"
    )
    
    # æ›´æ–°session state
    st.session_state.active_tab = active_tab
    
    if active_tab == "ğŸ¤– æ™ºèƒ½æ–‡æ¡£é—®ç­”":
        st.header("æ™ºèƒ½æ–‡æ¡£é—®ç­”")

        st.markdown("### ğŸ“ æ–‡æ¡£ä¸Šä¼ ")
        
        # è·å–æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        file_config = get_config("file")
        supported_formats = [fmt.lstrip('.') for fmt in file_config.get("supported_formats", ["pdf", "txt", "docx"])]
        
        uploaded_file = st.file_uploader(
            "é€‰æ‹©éœ€è¦é—®ç­”çš„æ–‡æ¡£",
            type=supported_formats,
            help="æ”¯æŒPDFã€Wordã€æ–‡æœ¬ç­‰æ ¼å¼",
            key="document_uploader"
        )
        
        if uploaded_file is not None:
            # æ–‡ä»¶ä¿¡æ¯
            st.success(f"âœ… æ–‡æ¡£å·²åŠ è½½: **{uploaded_file.name}**")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ–‡ä»¶å¤§å°", f"{uploaded_file.size:,} å­—èŠ‚")
            with col2:
                st.metric("æ–‡ä»¶ç±»å‹", Path(uploaded_file.name).suffix.upper())
            with col3:
                st.metric("AIç±»å‹", "ğŸ§  MCPæ™ºèƒ½" if agent_type == "MCPæ™ºèƒ½åŠ©æ‰‹" else "âš¡ ä¼ ç»Ÿé—®ç­”")
            
            st.markdown("---")
            
            # é—®ç­”åŒºåŸŸ
            st.markdown("### ğŸ’­ æ™ºèƒ½é—®ç­”")
            
            # é—®é¢˜è¾“å…¥
            question = st.text_area(
                "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜:",
                height=100,
                placeholder="ä¾‹å¦‚ï¼š\nâ€¢ è¿™ä¸ªæ–‡æ¡£çš„æ ¸å¿ƒè§‚ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ\nâ€¢ æåˆ°äº†å“ªäº›è§£å†³æ–¹æ¡ˆï¼Ÿ\nâ€¢ æœ‰å“ªäº›é‡è¦çš„ç»Ÿè®¡æ•°æ®ï¼Ÿ\nâ€¢ ä½œè€…å»ºè®®é‡‡å–ä»€ä¹ˆè¡ŒåŠ¨ï¼Ÿ",
                help="ç”¨è‡ªç„¶è¯­è¨€æè¿°æ‚¨æƒ³äº†è§£çš„å†…å®¹"
            )
            
            # é«˜çº§é€‰é¡¹
            with st.expander("ğŸ”§ é«˜çº§é€‰é¡¹"):
                col1, col2 = st.columns(2)
                with col1:
                    answer_style = st.selectbox(
                        "å›ç­”é£æ ¼",
                        ["detailed", "concise", "bullet_points"],
                        format_func=lambda x: {
                            "detailed": "ğŸ“ è¯¦ç»†è§£é‡Š",
                            "concise": "ğŸ’¡ ç®€æ´æ˜äº†", 
                            "bullet_points": "ğŸ“‹ è¦ç‚¹åˆ—è¡¨"
                        }[x]
                    )
                with col2:
                    include_quotes = st.checkbox("ğŸ“– åŒ…å«åŸæ–‡å¼•ç”¨", value=True)
                    confidence_threshold = st.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.3, 1.0, 0.7, 0.1)
                
                # é«˜çº§ç½®ä¿¡åº¦è¯„ä¼°å¼€å…³ï¼ˆé»˜è®¤å…³é—­ä»¥æå‡é€Ÿåº¦ï¼‰
                enable_advanced_confidence = st.checkbox("âš™ï¸ å¯ç”¨é«˜çº§ç½®ä¿¡åº¦è¯„ä¼°ï¼ˆè¾ƒæ…¢ï¼‰", value=False, help="å¼€å¯åå°†è°ƒç”¨é¢å¤–ä¸€æ¬¡æ¨¡å‹å¯¹ç­”æ¡ˆè¿›è¡Œç½®ä¿¡åº¦æ‰“åˆ†ï¼Œå¯èƒ½æ˜¾è‘—å¢åŠ å“åº”æ—¶é—´")
                
                # RAG ç›¸å…³å‚æ•°
                use_rag = st.checkbox("å¯ç”¨RAG", value=True)
                col3, col4, col5 = st.columns(3)
                with col3:
                    rag_top_k = st.slider("å‘é‡å¬å›TopK", 4, 30, 12, 1)
                with col4:
                    use_reranker = st.checkbox("å¯ç”¨é‡æ’", value=True)
                with col5:
                    rag_rerank_top_n = st.slider("é‡æ’åç‰‡æ®µæ•°", 2, 12, 6, 1)
                
                # MCPç‰¹å®šé€‰é¡¹
                if agent_type == "MCPæ™ºèƒ½åŠ©æ‰‹":
                    st.markdown("**MCPé«˜çº§è®¾ç½®**")
                    col6, col7 = st.columns(2)
                    with col6:
                        max_iterations = st.number_input("æœ€å¤§æ€è€ƒè½®æ•°", min_value=3, max_value=20, value=10)
                    with col7:
                        show_thinking = st.checkbox("æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹", value=True)
        
        # é—®ç­”æŒ‰é’®
        button_text = "ğŸ§  å¼€å§‹æ·±åº¦åˆ†æ" if agent_type == "MCPæ™ºèƒ½åŠ©æ‰‹" else "ğŸ” å¼€å§‹é—®ç­”"
        if st.button(button_text, type="primary", use_container_width=True):
            if not question:
                st.error("è¯·è¾“å…¥é—®é¢˜å†…å®¹ï¼")
                return
            
            # æ ¹æ®é€‰æ‹©çš„Agentç±»å‹æ‰§è¡Œä¸åŒçš„å¤„ç†æµç¨‹
            if agent_type == "MCPæ™ºèƒ½åŠ©æ‰‹":
                # MCPæ™ºèƒ½ä½“å¤„ç†æµç¨‹
                run_async_in_streamlit(
                    process_mcp_qa(uploaded_file, question, mcp_agent, 
                                 answer_style, include_quotes, confidence_threshold,
                                 max_iterations if 'max_iterations' in locals() else 10,
                                 show_thinking if 'show_thinking' in locals() else True,
                                 use_rag, use_reranker, rag_top_k, rag_rerank_top_n)
                )
            else:
                # ä¼ ç»Ÿé—®ç­”å¤„ç†æµç¨‹
                with st.spinner("ğŸ”„ AIæ­£åœ¨åˆ†ææ–‡æ¡£å¹¶å‡†å¤‡ç­”æ¡ˆ..."):
                    run_async_in_streamlit(
                        process_document_qa(
                            uploaded_file,
                            question,
                            answer_style,
                            include_quotes,
                            confidence_threshold,
                            enable_advanced_confidence,
                            use_rag,
                            use_reranker,
                            rag_top_k,
                            rag_rerank_top_n,
                        )
                    )
                
        else:
            # ä¸Šä¼ æç¤º
            st.markdown("""
            <div style="border: 2px dashed #ccc; border-radius: 10px; padding: 3rem; text-align: center; margin: 2rem 0;">
                <h3 style="color: #666;">ğŸ¤– æ™ºèƒ½é—®ç­”åŠ©æ‰‹</h3>
                <p style="color: #888;">ä¸Šä¼ æ–‡æ¡£åå³å¯å¼€å§‹æ™ºèƒ½é—®ç­”</p>
                <p style="font-size: 0.9rem; color: #aaa;">æ”¯æŒå¤æ‚é—®é¢˜å’Œå¤šè½®å¯¹è¯</p>
            </div>
            """, unsafe_allow_html=True)
            
            # Agentç±»å‹è¯´æ˜
            if agent_type == "MCPæ™ºèƒ½åŠ©æ‰‹":
                st.markdown("#### ğŸ§  MCPæ™ºèƒ½åŠ©æ‰‹ç‰¹æ€§")
                st.info("""
                **MCPæ™ºèƒ½åŠ©æ‰‹å…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š**
                - ğŸ¤” **æ·±åº¦æ€è€ƒ**ï¼šå¤šè½®åˆ†ææ¨ç†è¿‡ç¨‹
                - ğŸ”§ **å·¥å…·è°ƒç”¨**ï¼šè‡ªåŠ¨ä½¿ç”¨æ–‡æ¡£åˆ†æã€æœç´¢ç­‰å·¥å…·
                - ğŸ“Š **è¿‡ç¨‹é€æ˜**ï¼šå®æ—¶æ˜¾ç¤ºæ€è€ƒå’Œæ‰§è¡Œè¿‡ç¨‹
                - ğŸ¯ **æ™ºèƒ½å†³ç­–**ï¼šæ ¹æ®é—®é¢˜å¤æ‚åº¦è‡ªåŠ¨é€‰æ‹©å¤„ç†ç­–ç•¥
                """)
            
            # é—®ç­”ç¤ºä¾‹
            st.markdown("#### ğŸ’¡ é—®ç­”ç¤ºä¾‹")
            examples = [
                "è¿™ä¸ªæ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ",
                "æ–‡æ¡£ä¸­æåˆ°äº†å“ªäº›é‡è¦æ•°æ®ï¼Ÿ",
                "ä½œè€…çš„ä¸»è¦è§‚ç‚¹å’Œç»“è®ºæ˜¯ä»€ä¹ˆï¼Ÿ", 
                "æœ‰ä»€ä¹ˆé‡è¦çš„å»ºè®®æˆ–æ¨èï¼Ÿ"
            ]
            
            for example in examples:
                st.info(f"**é—®é¢˜ç¤ºä¾‹**: {example}")

    elif active_tab == "ğŸ“Š æ™ºèƒ½æ•°æ®åˆ†æ":
        st.header("æ™ºèƒ½æ•°æ®åˆ†æ")

        st.markdown("### ğŸ“ æ–‡æ¡£ä¸Šä¼ ")
        
        data_uploader = st.file_uploader(
            "ä¸Šä¼ æ‚¨çš„æ•°æ®æ–‡ä»¶", 
            type=["xlsx", "xls"],
            key="data_uploader"
        )
        
        if data_uploader is not None:
            st.success(f"âœ… æ•°æ®æ–‡ä»¶å·²åŠ è½½: **{data_uploader.name}**")
            
            # åˆ†æè¦æ±‚è¾“å…¥
            analysis_requirements = st.text_area(
                "è¯·è¾“å…¥æ‚¨çš„åˆ†æè¦æ±‚",
                height=100,
                placeholder="ä¾‹å¦‚ï¼š\nâ€¢ å¸®æˆ‘åˆ†æé”€å”®é¢å’Œå¹¿å‘ŠæŠ•å…¥çš„å…³ç³»\nâ€¢ æ‰¾å‡ºå“ªäº›äº§å“çš„åˆ©æ¶¦ç‡æœ€é«˜\nâ€¢ åˆ†ææ•°æ®ä¸­çš„è¶‹åŠ¿å’Œå¼‚å¸¸å€¼",
                key="analysis_requirements"
            )
            
            # é«˜çº§é€‰é¡¹
            with st.expander("ğŸ”§ é«˜çº§é€‰é¡¹"):
                col1, col2, col3 = st.columns(3)
                with col1:
                    max_iterations = st.slider("æœ€å¤§æ€è€ƒè½®æ•°", 5, 20, 10, key="data_max_iter")
                with col2:
                    show_thinking = st.checkbox("æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹", value=True, key="data_show_thinking")
                with col3:
                    confidence_threshold = st.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.1, 1.0, 0.7, key="data_confidence")
                
                # RAG ç›¸å…³å‚æ•°
                st.markdown("**RAGè®¾ç½®**")
                col4, col5, col6 = st.columns(3)
                with col4:
                    use_rag = st.checkbox("å¯ç”¨RAG", value=True, key="data_use_rag")
                with col5:
                    use_reranker = st.checkbox("å¯ç”¨é‡æ’", value=True, key="data_use_reranker")
                with col6:
                    rag_top_k = st.slider("RAG TopK", 4, 20, 8, key="data_rag_top_k")
                rag_rerank_top_n = st.slider("é‡æ’åç‰‡æ®µæ•°", 2, 10, 4, key="data_rag_rerank_n")
            
            # å¼€å§‹åˆ†ææŒ‰é’®
            if st.button("ğŸ§  å¼€å§‹æ·±åº¦åˆ†æ", type="primary", use_container_width=True, key="data_analysis_button"):
                if not analysis_requirements.strip():
                    st.warning("âš ï¸ è¯·å…ˆè¾“å…¥åˆ†æè¦æ±‚")
                else:
                    # æ ¹æ®é€‰æ‹©çš„Agentç±»å‹æ‰§è¡Œä¸åŒçš„å¤„ç†æµç¨‹
                    if agent_type == "MCPæ™ºèƒ½åŠ©æ‰‹":
                        if mcp_agent is None:
                            st.error("âŒ MCPæ™ºèƒ½ä½“æœªåˆå§‹åŒ–")
                        else:
                            run_async_in_streamlit(
                                process_mcp_data_analysis(data_uploader, analysis_requirements, mcp_agent, 
                                                        max_iterations=max_iterations, show_thinking=show_thinking,
                                                        confidence_threshold=confidence_threshold,
                                                        use_rag=use_rag, use_reranker=use_reranker,
                                                        rag_top_k=rag_top_k, rag_rerank_top_n=rag_rerank_top_n)
                            )
                    else:
                        st.warning("ğŸ’¡ æ•°æ®åˆ†æå½“å‰ä»…æ”¯æŒMCPæ™ºèƒ½åŠ©æ‰‹æ¨¡å¼")
        
        else:
            # ä¸Šä¼ æç¤º
            st.markdown("""
            <div style="border: 2px dashed #ccc; border-radius: 10px; padding: 3rem; text-align: center; margin: 2rem 0;">
                <h3 style="color: #666;">ğŸ“Š æ™ºèƒ½æ•°æ®åˆ†æ</h3>
                <p style="color: #888;">ä¸Šä¼ æ•°æ®æ–‡ä»¶åå³å¯å¼€å§‹æ™ºèƒ½æ•°æ®åˆ†æ</p>
                <p style="font-size: 0.9rem; color: #aaa;">æ”¯æŒå¤æ‚åˆ†æå’Œå¤šè½®æ¨ç†</p>
            </div>
            """, unsafe_allow_html=True)
            
            # æ•°æ®åˆ†æç¤ºä¾‹
            st.markdown("#### ğŸ’¡ æ•°æ®åˆ†æç¤ºä¾‹")
            examples = [
                "å¸®æˆ‘åˆ†æé”€å”®é¢å’Œå¹¿å‘ŠæŠ•å…¥çš„å…³ç³»",
                "æ‰¾å‡ºå“ªäº›äº§å“çš„åˆ©æ¶¦ç‡æœ€é«˜",
                "åˆ†ææ•°æ®ä¸­çš„è¶‹åŠ¿å’Œå¼‚å¸¸å€¼",
                "é¢„æµ‹ä¸‹ä¸ªå­£åº¦çš„é”€å”®å¢é•¿",
            ]
            
            for example in examples:
                st.info(f"**åˆ†æç¤ºä¾‹**: {example}")

if __name__ == "__main__":
    main()
