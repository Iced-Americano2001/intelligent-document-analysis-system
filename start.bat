@echo off
echo ğŸ“„ å¯åŠ¨æ–‡æ¡£åˆ†æç³»ç»Ÿ...

REM æ£€æŸ¥Pythonç¯å¢ƒ
python --version >nul 2>&1
if errorlevel 1 (
    echo âŒ é”™è¯¯: æœªæ‰¾åˆ°Python
    echo è¯·å®‰è£…Python 3.8æˆ–æ›´é«˜ç‰ˆæœ¬
    pause
    exit /b 1
)

REM æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ
if "%VIRTUAL_ENV%"=="" (
    echo âš ï¸  å»ºè®®åœ¨è™šæ‹Ÿç¯å¢ƒä¸­è¿è¡Œæ­¤åº”ç”¨
    echo åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ: python -m venv venv
    echo æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ: venv\Scripts\activate
    echo.
)

REM åˆ›å»ºå¿…è¦çš„ç›®å½•
echo ğŸ“ åˆ›å»ºå¿…è¦çš„ç›®å½•...
if not exist "uploads" mkdir uploads
if not exist "logs" mkdir logs
if not exist "temp" mkdir temp

REM æ£€æŸ¥ä¾èµ–
echo ğŸ“¦ æ£€æŸ¥ä¾èµ–...
pip install -r requirements.txt
if errorlevel 1 (
    echo âŒ ä¾èµ–å®‰è£…å¤±è´¥
    pause
    exit /b 1
)

REM æ£€æŸ¥OllamaæœåŠ¡ï¼ˆå¦‚æœä½¿ç”¨ï¼‰
where ollama >nul 2>&1
if not errorlevel 1 (
    echo ğŸ¤– æ£€æŸ¥OllamaæœåŠ¡...
    ollama list >nul 2>&1
    if errorlevel 1 (
        echo âš ï¸  OllamaæœåŠ¡æœªè¿è¡Œï¼Œæ­£åœ¨å¯åŠ¨...
        start /B ollama serve
        timeout /t 5 >nul
    )
    
    REM æ£€æŸ¥æ¨¡å‹
    ollama list | findstr "llama3.2" >nul
    if errorlevel 1 (
        echo ğŸ“¥ ä¸‹è½½llama3.2æ¨¡å‹...
        ollama pull llama3.2
    )
) else (
    echo â„¹ï¸  æœªå®‰è£…Ollamaï¼Œå°†ä½¿ç”¨OpenAI API
)

REM è®¾ç½®ç¯å¢ƒå˜é‡
set PYTHONPATH=%PYTHONPATH%;%CD%

REM å¯åŠ¨åº”ç”¨
echo ğŸš€ å¯åŠ¨Streamlitåº”ç”¨...
streamlit run app.py --server.port 8501 --server.address 0.0.0.0

echo âœ… å¯åŠ¨å®Œæˆï¼
echo ğŸŒ è®¿é—®åœ°å€: http://localhost:8501
pause
